#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import pathlib
import sys
from datetime import datetime
from pathlib import Path
from typing import List

import arrow
import pandas as pd
from apscheduler.schedulers.blocking import BlockingScheduler

from conf.settings import TASK_OPTIONS
from conf.store_conf import STORE_OPTIONS
from core.data import SpiderTask, GTSSurgeRealData
from schemas.surge import GTSPointSchema, GTSEntiretySchema

# --- é…ç½®åŒºåŸŸ ---
# ä½¿ç”¨ pathlib.Path å®šä¹‰è·¯å¾„
BASE_DATA_PATH = Path("/root/Decoded_Data")
# è¦æå–çš„æœ€æ–°æ•°æ®ç‚¹æ•°é‡
RECORDS_TO_EXTRACT = 180


# --- é…ç½®åŒºåŸŸç»“æŸ ---
def round_timestamp_to_nearest_second_bakup(timestamp_str: str) -> str:
    """
    ä½¿ç”¨ arrow åº“å°†ä¸€ä¸ª ISO 8601 æ ¼å¼çš„æ—¶é—´æˆ³å­—ç¬¦ä¸²å››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„ç§’ã€‚

    Args:
        timestamp_str: åŸå§‹æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "2025-08-13T02:15:59.616000+00:00"ã€‚

    Returns:
        å¤„ç†åçš„æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "2025-08-13T02:16:00+00:00"ã€‚
    """
    try:
        arrow_obj = arrow.get(timestamp_str)
        # 2. ç›´æ¥è°ƒç”¨ round() æ–¹æ³•ï¼ŒæŒ‡å®šå•ä½ä¸º 'second'
        rounded_arrow_obj = arrow_obj.ceil('second')
        # 3. æ ¼å¼åŒ–å›æ ‡å‡†çš„ ISO 8601 å­—ç¬¦ä¸²
        return rounded_arrow_obj.isoformat()
    except (arrow.parser.ParserError, TypeError):
        print(f"è­¦å‘Š (arrow)ï¼šæ— æ³•è§£ææ—¶é—´æˆ³ '{timestamp_str}'ï¼Œå°†ä¿æŒåŸæ ·ã€‚")
        return timestamp_str


def round_dtstr_to_nearest_second(ts: arrow.Arrow) -> str:
    """
        å°† arrow æ—¶é—´å¯¹è±¡å››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„ç§’ã€‚
        åŸç†ï¼šç»™æ—¶é—´æˆ³åŠ ä¸Š500,000å¾®ç§’ï¼ˆåŠç§’ï¼‰ï¼Œ
              ç„¶åå¯¹ç§’è¿›è¡Œå‘ä¸‹å–æ•´ã€‚
    @param ts:
    @return:
    """
    rounded_ts = round_timestamp_to_nearest_second(ts)
    formatted_ts = rounded_ts.format("YYYY-MM-DDTHH:mm:ss")
    return formatted_ts


def round_arrow_to_nearest_second(ts: arrow.Arrow) -> arrow.Arrow:
    """
        å°† arrow æ—¶é—´å¯¹è±¡å››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„ç§’ã€‚
        åŸç†ï¼šç»™æ—¶é—´æˆ³åŠ ä¸Š500,000å¾®ç§’ï¼ˆåŠç§’ï¼‰ï¼Œ
              ç„¶åå¯¹ç§’è¿›è¡Œå‘ä¸‹å–æ•´ã€‚
    @param ts:
    @return:
    """
    rounded_ts = round_timestamp_to_nearest_second(ts)
    arrow_utc = arrow.get(rounded_ts)
    return arrow_utc


def round_timestamp_to_nearest_second(ts: arrow.Arrow) -> arrow.Arrow:
    """
        å°† arrow æ—¶é—´å¯¹è±¡å››èˆäº”å…¥åˆ°æœ€æ¥è¿‘çš„ç§’ã€‚
        åŸç†ï¼šç»™æ—¶é—´æˆ³åŠ ä¸Š500,000å¾®ç§’ï¼ˆåŠç§’ï¼‰ï¼Œ
              ç„¶åå¯¹ç§’è¿›è¡Œå‘ä¸‹å–æ•´ã€‚
    @param ts:
    @return:
    """
    rounded_ts = ts.shift(microseconds=500000).floor('second')
    return rounded_ts


def get_latest_sea_level_data(root_dir: Path, now_utc: arrow.Arrow) -> List[GTSEntiretySchema]:
    """
            ä½¿ç”¨ pandas, arrow å’Œ pathlib æå–å½“å‰æ—¥æœŸç›®å½•ä¸‹æ‰€æœ‰ç«™ç‚¹çš„
            æœ€æ–°20æ¡æµ·å¹³é¢æ•°æ®ã€‚
            eg:
                {'dber': {'station_code': 'dber',
                'sensor_type': 'bwl',
                'source_file': 'dber.bwl.238',
                'data_points':
                [{'timestamp_utc': '2025-08-26T01:15:00', 'sea_level_meters': 5222.706},
                 {'timestamp_utc': '2025-08-26T01:30:00','sea_level_meters': 5222.717},
                 {'timestamp_utc': '2025-08-26T01:45:00', 'sea_level_meters': 5222.724},
                 {'timestamp_utc': '2025-08-26T02:00:00', 'sea_level_meters': 5222.727},
                 {'timestamp_utc': '2025-08-26T02:15:00', 'sea_level_meters': 5222.72},
                 }
    @param root_dir:
    @param now_utc:
    @return:
    """
    try:
        # 1. ä½¿ç”¨ arrow è·å–å½“å‰UTCæ—¶é—´å¹¶è®¡ç®—DOY
        day_of_year = now_utc.timetuple().tm_yday
        doy_str = f"{day_of_year:03d}"

        # 2. ä½¿ç”¨ pathlib æ„å»ºå½“å¤©çš„ç›®å½•è·¯å¾„
        today_dir = root_dir / doy_str

        if not today_dir.is_dir():
            print(f"é”™è¯¯ï¼šæ•°æ®ç›®å½• '{today_dir}' ä¸å­˜åœ¨ã€‚å¯èƒ½ä»Šå¤©çš„æ•°æ®å°šæœªç”Ÿæˆã€‚", file=sys.stderr)
            return None

        latest_data_collection: List[GTSEntiretySchema] = []

        # 3. éå†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        for file_path in today_dir.iterdir():
            if not file_path.is_file():
                continue

            # 4. è§£ææ–‡ä»¶å
            try:
                parts = file_path.name.split('.')
                if len(parts) != 3:
                    continue
                # TODO:[-] 25-09-08 é€šè¿‡æ–‡ä»¶åè·å–ä¼ æ„Ÿå™¨ç±»å‹
                station_code, sensor_type, _ = parts
            except ValueError:
                continue

            # 5. ä½¿ç”¨ pandas è¯»å–æ•´ä¸ªæ–‡ä»¶
            try:
                # read_csv å¯ä»¥æ™ºèƒ½å¤„ç†å¤šç§ç©ºç™½å­—ç¬¦ä½œä¸ºåˆ†éš”ç¬¦
                # header=None è¡¨ç¤ºæ–‡ä»¶æ²¡æœ‰æ ‡é¢˜è¡Œ
                # names æŒ‡å®šåˆ—å
                df = pd.read_csv(
                    file_path,
                    sep=r'\s+',  # æ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒ¹é…ä¸€ä¸ªæˆ–å¤šä¸ªç©ºç™½å­—ç¬¦
                    header=None,
                    names=['time_val', 'sea_level'],
                    engine='python',  # ä½¿ç”¨pythonå¼•æ“ä»¥æ”¯æŒå¤æ‚çš„sep
                    comment='*'  # å‡è®¾ä»¥'*'å¼€å¤´çš„è¡Œä¸ºæ³¨é‡Šè¡Œï¼Œå¯ä»¥å¿½ç•¥
                )

                # å¦‚æœæ–‡ä»¶ä¸ºç©ºæˆ–åªæœ‰æ³¨é‡Šè¡Œï¼Œdfä¼šæ˜¯ç©ºçš„
                if df.empty:
                    continue

            except Exception as e:
                print(f"è­¦å‘Šï¼šè¯»å–æˆ–è§£ææ–‡ä»¶ '{file_path.name}' æ—¶å‡ºé”™: {e}", file=sys.stderr)
                continue

            # sensor_type = file_path.name.split('.')[1]

            # 6. è·å–æœ€å N æ¡è®°å½• (å¦‚æœä¸è¶³Næ¡ï¼Œåˆ™è·å–æ‰€æœ‰è®°å½•)
            latest_records = df.tail(RECORDS_TO_EXTRACT)

            data_points: List[GTSPointSchema] = []
            start_of_year = now_utc.floor('year')

            # 7. éå†è¿™ N æ¡è®°å½•ï¼Œå¹¶è½¬æ¢ä¸ºæ‰€éœ€çš„æ ¼å¼
            for index, row in latest_records.iterrows():
                try:
                    time_val = float(row['time_val'])
                    sea_level = float(row['sea_level'])

                    # ä½¿ç”¨ arrow è®¡ç®—ç²¾ç¡®æ—¶é—´æˆ³
                    time_doy = int(time_val)
                    fraction_of_day = time_val - time_doy
                    total_seconds = (time_doy - 1) * 86400 + fraction_of_day * 86400
                    exact_timestamp = start_of_year.shift(seconds=total_seconds)

                    # TODO:[*] 25-08-28 æ­¤å¤„æœ‰é”™ï¼Œè¿”å›çš„ä¸º arrow.Arrow è€Œé int ç±»å‹
                    stanard_ts: int = round_arrow_to_nearest_second(exact_timestamp).int_timestamp
                    stanard_dt: datetime = round_arrow_to_nearest_second(exact_timestamp).datetime

                    # data_points.append({
                    #     "timestamp_utc": stanard_ts,
                    #     "sea_level_meters": sea_level
                    # })
                    data_points.append(
                        GTSPointSchema(timestamp_utc=stanard_ts, dt_utc=stanard_dt, sea_level_meters=sea_level))
                except (ValueError, TypeError):
                    # å¦‚æœæŸä¸€è¡Œæ•°æ®æ ¼å¼é”™è¯¯ï¼Œåˆ™è·³è¿‡è¯¥è¡Œ
                    print(f'[*] è¯»å–{file_path}ä¸­çš„:{time_val}é”™è¯¯ï¼')
                    continue

            # å¦‚æœæˆåŠŸå¤„ç†äº†ä»»ä½•æ•°æ®ç‚¹ï¼Œåˆ™æ·»åŠ åˆ°æœ€ç»ˆé›†åˆä¸­
            if data_points:
                # latest_data_collection[station_code] = {
                #     "station_code": station_code,
                #     "sensor_type": sensor_type,
                #     "source_file": file_path.name,
                #     "data_points": data_points
                # }
                latest_data_collection.append(
                    GTSEntiretySchema(station_code=station_code, sensor_type=sensor_type, source_file=file_path.name,
                                      data_points=data_points))
            pass

        return latest_data_collection

    except Exception as e:
        print(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", file=sys.stderr)
        return None


def run_timer_process_gtsdata():
    store_options: dict = STORE_OPTIONS.get('gts')
    dir_path_str: str = str(Path(store_options.get('path')) / store_options.get('relative_path'))
    dir_path: pathlib.Path = pathlib.Path(dir_path_str)
    out_put: pathlib.Path = pathlib.Path(r'/Users/evaseemefly/03data/02station') / 'all_station_225.json'
    now_utc: arrow.Arrow = arrow.utcnow()
    """
        {'data_points': [{'sea_level_meters': 4125.162, 'timestamp_utc': '2025-08-26T00:00:00'}], 'sensor_type': 'bwl', 'source_file': 'dch3.bwl.238', 'station_code': 'dch3'}
        {'dber': {'station_code': 'dber', 
                'sensor_type': 'bwl', 
                'source_file': 'dber.bwl.238', 
                'data_points': 
                [{'timestamp_utc': '2025-08-26T01:15:00', 'sea_level_meters': 5222.706}, 
                 {'timestamp_utc': '2025-08-26T01:30:00','sea_level_meters': 5222.717}, 
                 {'timestamp_utc': '2025-08-26T01:45:00', 'sea_level_meters': 5222.724}, 
                 {'timestamp_utc': '2025-08-26T02:00:00', 'sea_level_meters': 5222.727}, 
                 {'timestamp_utc': '2025-08-26T02:15:00', 'sea_level_meters': 5222.72}, 

    """
    # step1: å®šæ—¶æ‰¹é‡è·å–æœ€æ–°çš„gtsæ•°æ®
    # TODO:[-] 25-08-27 æ­¤å¤„ç”± dict -> json ä¿®æ”¹ä¸º=> -> schema
    all_stations_latest_data: List[GTSEntiretySchema] = get_latest_sea_level_data(dir_path, now_utc)

    # TODO:[*] 25-08-27 å°†å½“å‰æ—¶åˆ»çš„æ‰€æœ‰å®å†µå†™å…¥ db
    # è½®è®­æ‰€æœ‰ç«™ç‚¹å¹¶åˆ†æ‰¹å†™å…¥
    for temp_station in all_stations_latest_data:
        temp_code: str = temp_station.station_code
        temp_realdata: List[GTSPointSchema] = temp_station.data_points
        temp_sensor: str = temp_station.sensor_type
        # step2: å°†è§£æåçš„gtsæ•°æ®é›† task ä»¥åŠ gts data å†™å…¥ db
        now_utc: arrow.Arrow = arrow.Arrow.utcnow()
        date_utc_ymdhm: str = now_utc.format('YYYYMMDDHHmm')
        task_name_prefix: str = TASK_OPTIONS.get('name_prefix')
        task_name: str = f'{task_name_prefix}{date_utc_ymdhm}'
        # step2-1 å†™å…¥ task
        # tid: int = -1
        # TODO:[*] 25-09-02 æ­¤å¤„åŠ å…¥å†™å…¥ task åˆ—è¡¨çš„æµç¨‹
        task_info = SpiderTask(now_utc, len(all_stations_latest_data), task_name)
        tid = task_info.to_db()
        # step2-2 å†™å…¥ realdata
        stationSurge = GTSSurgeRealData(temp_station, tid, temp_sensor)
        # step1: åˆ›å»ºåˆ†è¡¨
        # stationSurge.create_split_tab()
        # step2: åƒ station_realdata_specific è¡¨ä¸­å†™å…¥å½“å‰å®å†µæ•°æ®
        stationSurge.insert_realdata_list(to_coverage=True, realdata_list=temp_realdata)
        pass

    # if all_stations_latest_data:
    #     try:
    #         with open(str(out_put), 'w', encoding='utf-8') as f:
    #             # ä½¿ç”¨ json.dump å°†æ•°æ®å†™å…¥æ–‡ä»¶
    #             # indent=4 ä½¿æ–‡ä»¶æ ¼å¼åŒ–ï¼Œæ˜“äºé˜…è¯»
    #             # ensure_ascii=False ç¡®ä¿ä¸­æ–‡å­—ç¬¦æˆ–ç‰¹æ®Šç¬¦å·ç›´æ¥å†™å…¥ï¼Œè€Œä¸æ˜¯è½¬ä¹‰
    #             json.dump(all_stations_latest_data, f, indent=4, ensure_ascii=False)
    #         print(f"æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶: {str(out_put)}")
    #     except Exception as e:
    #         print(f"\né”™è¯¯ï¼šå†™å…¥JSONæ–‡ä»¶ '{str(out_put)}' æ—¶å¤±è´¥: {e}")


if __name__ == "__main__":
    # æµ‹è¯•ç«‹åˆ»æ‰§è¡Œ
    # run_timer_process_gtsdata()
    # pass
    # 1. åˆ›å»ºä¸€ä¸ªè°ƒåº¦å™¨å®ä¾‹
    scheduler = BlockingScheduler(timezone="UTC")  # å»ºè®®æŒ‡å®šæ—¶åŒº

    # 2. æ·»åŠ ä»»åŠ¡
    # 'cron' è§¦å‘å™¨åŠŸèƒ½å¼ºå¤§ï¼Œå¯ä»¥åƒLinuxçš„crontabä¸€æ ·è®¾ç½®
    # minute=0 è¡¨ç¤ºåœ¨æ¯å°æ—¶çš„ç¬¬0åˆ†é’Ÿæ‰§è¡Œ
    # scheduler.add_job(run_timer_process_gtsdata, 'cron', hour='*', minute=0)

    # --- å…¶ä»–å¸¸ç”¨è°ƒåº¦ç¤ºä¾‹ (ä¾›å‚è€ƒ) ---
    scheduler.add_job(run_timer_process_gtsdata, 'interval', minutes=30)  # æ¯10åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡
    # scheduler.add_job(run_main_task, 'cron', day_of_week='mon-fri', hour=17, minute=30) # æ¯å‘¨ä¸€åˆ°å‘¨äº”17:30æ‰§è¡Œ

    print("âœ… APScheduler è°ƒåº¦å™¨å·²å¯åŠ¨ã€‚ç­‰å¾…ä¸‹ä¸€ä¸ªæ•´ç‚¹æ‰§è¡Œ...")

    try:
        # 3. å¯åŠ¨è°ƒåº¦å™¨ (è¿™æ˜¯ä¸€ä¸ªé˜»å¡æ“ä½œï¼Œä¼šä¸€ç›´è¿è¡Œ)
        scheduler.start()
    except (KeyboardInterrupt, SystemExit):
        # ä¼˜é›…åœ°å…³é—­è°ƒåº¦å™¨
        scheduler.shutdown()
        print("ğŸ›‘ è°ƒåº¦å™¨å·²å…³é—­ã€‚")
